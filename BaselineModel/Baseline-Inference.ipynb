{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e4c80c-7123-402e-936f-9c11d6dd0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import glob\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec83c8af-b1fb-47e8-b9e5-962e1e5774bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "so = onnxruntime.SessionOptions()\n",
    "so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_session = onnxruntime.InferenceSession(\"nsnetv2_converted.onnx\", so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6493b44-20cf-4310-92ec-f2a9a69fef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "def stft(signal, frame_size = 160, window_size = 320):\n",
    "        window = np.sqrt(np.hanning(window_size + 1)[:-1]).astype(np.float32)\n",
    "\n",
    "        last_frame = len(signal) % frame_size\n",
    "        if last_frame == 0:\n",
    "            last_frame = frame_size\n",
    "\n",
    "        padded_signal = np.pad(signal, ((window_size - frame_size, window_size - last_frame),))\n",
    "        frames = librosa.util.frame(padded_signal, len(window), frame_size, axis=0)\n",
    "        spec = scipy.fft.rfft(frames * window, n=window_size)\n",
    "        return spec                  \n",
    "\n",
    "def istft(signal, frame_size = 160, window_size = 320):\n",
    "    window = np.sqrt(np.hanning(window_size + 1)[:-1]).astype(np.float32)\n",
    "    frames = scipy.fft.irfft(signal, axis=-1)\n",
    "    \n",
    "    # crop frames if dft_size is larger than window_size\n",
    "    frames = frames[:, :window_size] * window\n",
    "\n",
    "    n_parts = window_size // frame_size\n",
    "\n",
    "    assert frames.shape[0] >= n_parts\n",
    "\n",
    "    target = frames[n_parts - 1:, :frame_size].copy()\n",
    "    for n in range(1, n_parts):\n",
    "        offset = n * frame_size\n",
    "        target += frames[n_parts - 1 - n:-n, offset:offset + frame_size]\n",
    "\n",
    "    # flatten the result\n",
    "    target.shape = target.size,\n",
    "    return target    \n",
    "  \n",
    "def logpow_msrtc(sig):\n",
    "    pspec = np.maximum(sig**2, 1e-12)\n",
    "    return np.log10(pspec)    \n",
    "    \n",
    "def build_features_logspec_plcmask(signal, is_lost):\n",
    "    signal_stft = stft(signal)\n",
    "    feat = np.abs(signal_stft)\n",
    "    feat_logpow = logpow_msrtc(feat)\n",
    "    \n",
    "    feat_angle = np.angle(signal_stft)\n",
    "    feat_phasor = np.stack([np.sin(feat_angle), np.cos(feat_angle)], axis=-1)  \n",
    "\n",
    "    # packet loss indicator mask\n",
    "    is_lost_frame_arr = np.repeat(is_lost, 2)\n",
    "    num_freqs = feat_logpow.shape[1]\n",
    "\n",
    "    def arr_to_mask(arr):\n",
    "        return np.repeat(np.expand_dims(arr, 1), num_freqs, axis=1)\n",
    "\n",
    "    left_mask = arr_to_mask(np.append(0, is_lost_frame_arr))\n",
    "    right_mask = arr_to_mask(np.append(is_lost_frame_arr, 0))\n",
    "\n",
    "    return [feat_logpow, left_mask, right_mask, feat_phasor[:, :, 0], feat_phasor[:, :, 1]], [feat, feat_phasor[:, :, 0], feat_phasor[:, :, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61aacdf5-d4d2-47c5-8288-839a43f1afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 966/966 [02:48<00:00,  5.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "wav_files = glob.glob(r\"blind\\lossy_signals\\*.wav\")\n",
    "out_dir = \"blind_out\"\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "for file in tqdm.tqdm(wav_files):\n",
    "    data, _ = sf.read(file)\n",
    "    lost_file = file.split(\".wav\")[0] + \"_is_lost.txt\"\n",
    "    loss_mask = np.loadtxt(lost_file)\n",
    "        \n",
    "    feats, feats_recon = build_features_logspec_plcmask(data, loss_mask)\n",
    "    feats = np.array(feats).swapaxes(0, 1)\n",
    "    feats = feats.reshape(feats.shape[0], -1)\n",
    "    \n",
    "    feats_recon = np.array(feats_recon).swapaxes(0, 1)\n",
    "    feats_recon = feats_recon.reshape(feats_recon.shape[0], -1)\n",
    "    \n",
    "    h0 = np.zeros((1, 1, 134))\n",
    "    h1 = np.zeros((1, 1, 100))\n",
    "    result = []\n",
    "    for idx, feat_row in enumerate(feats):\n",
    "        feat_row = feat_row.reshape(1, 1, -1)\n",
    "        ort_inputs = {\"input\": feat_row.astype(np.float32), \"h01\": h0.astype(np.float32), \"h02\": h1.astype(np.float32)}\n",
    "        y, h0, h1 = ort_session.run(None, ort_inputs)\n",
    "        if idx // 2 >= len(loss_mask) or loss_mask[idx // 2] == 0:\n",
    "            y = feats_recon[idx, :].reshape(y.shape)\n",
    "        else:\n",
    "            y = y\n",
    "        y_abs, y_sin, y_cos = np.split(y, 3, axis=1)\n",
    "        y_complex = y_abs * (y_cos + 1j * y_sin)\n",
    "        result.append(y_complex)\n",
    "    result = istft(np.array(result).squeeze())\n",
    "    sf.write(os.path.join(out_dir, os.path.basename(file)), result, 16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
